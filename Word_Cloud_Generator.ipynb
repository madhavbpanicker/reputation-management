{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdc9f5c-3236-47f8-bf09-85b93ab7456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/madhavbpanicker/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/madhavbpanicker/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a7f0b6-9cd8-4ae3-9968-9761cd4ffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file with scraped pages\n",
    "file_path = 'web_pages.csv'  # Replace with the path to your CSV file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the HTML column exists\n",
    "html_column = 'page_content'  # Replace with the actual column name containing HTML data\n",
    "if html_column not in data.columns:\n",
    "    raise ValueError(f\"The specified column '{html_column}' does not exist in the CSV file.\")\n",
    "\n",
    "# Fill missing or invalid HTML values with empty strings\n",
    "data[html_column] = data[html_column].fillna('')\n",
    "html_data = data[html_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ae424b-790a-4f9c-86e9-c0a649bef2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Paragraphs Containing Reviews\n",
    "all_reviews = []\n",
    "def extract_reviews(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    reviews = []\n",
    "    for p in paragraphs:\n",
    "        text = p.get_text().strip()\n",
    "        if text:  # Non-empty text\n",
    "            reviews.append(text)\n",
    "    return reviews\n",
    "\n",
    "# Process all HTML data\n",
    "for html in html_data:\n",
    "    all_reviews.extend(extract_reviews(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4ca403-130d-42ed-b1e0-a85767b3b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentiment: 0.17844992397832807\n"
     ]
    }
   ],
   "source": [
    "#Perform Sentiment Analysis\n",
    "sentiments = []\n",
    "for review in all_reviews:\n",
    "    analysis = TextBlob(review)\n",
    "    sentiments.append(analysis.sentiment.polarity)\n",
    "\n",
    "# Calculate the average sentiment\n",
    "average_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0\n",
    "print(f\"Average Sentiment: {average_sentiment}\")\n",
    "\n",
    "### Cell 5: Extract Keywords\n",
    "keywords = []\n",
    "def extract_keywords(text):\n",
    "    words = [word.lower() for word in TextBlob(text).words if word.lower() not in stop_words and word.isalpha()]\n",
    "    return words\n",
    "\n",
    "# Process reviews to extract keywords\n",
    "for review in all_reviews:\n",
    "    keywords.extend(extract_keywords(review))\n",
    "\n",
    "# Count keyword occurrences\n",
    "keyword_counts = Counter(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0c08ac9-1744-4012-b98e-971ae2af114e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7e49af9a8c80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Cloud generation\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(keyword_counts)\n",
    "\n",
    "# Display the word cloud\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#plt.axis('off')\n",
    "#plt.title('Word Cloud for Hyundai Reviews')\n",
    "#plt.show()\n",
    "\n",
    "# Save word cloud image\n",
    "wordcloud_image_path = 'wordcloud.png'\n",
    "wordcloud.to_file(wordcloud_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f770bdd2-639e-40eb-90f4-3a5e801f8240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "# Define the S3 bucket and paths\n",
    "s3_bucket = 'madhavbpanicker'  # Replace with your S3 bucket name\n",
    "results_path = 'results/'\n",
    "\n",
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Save sentiment results and keywords\n",
    "results = {\n",
    "    'average_sentiment': average_sentiment,\n",
    "    'keywords': keyword_counts\n",
    "}\n",
    "results_json = json.dumps(results)\n",
    "\n",
    "# Upload results JSON\n",
    "results_json_path = 'sentiment_results.json'\n",
    "with open(results_json_path, 'w') as f:\n",
    "    f.write(results_json)\n",
    "\n",
    "s3.upload_file(results_json_path, s3_bucket, f'{results_path}{results_json_path}')\n",
    "\n",
    "# Upload word cloud image\n",
    "s3.upload_file(wordcloud_image_path, s3_bucket, f'{results_path}{wordcloud_image_path}')\n",
    "\n",
    "print(\"Results uploaded to S3.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
